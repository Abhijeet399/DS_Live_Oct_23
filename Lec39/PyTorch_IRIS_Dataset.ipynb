{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ZiXkV1JwBAFc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "mN62QDi_Sm7b"
   },
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "MjTW4XISS0NY"
   },
   "outputs": [],
   "source": [
    "X, Y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gyMfD5YaS7P3",
    "outputId": "263a932d-150c-403b-97f8-c8e32f72a6b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3LkYDxRCS8YT"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zDluQ0HVS-Hy",
    "outputId": "518ed4a6-5ef8-4075-bb1f-6dbab0f8a0c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 2, 0, 2, 1, 2, 1,\n",
       "       1, 1, 2, 0, 1, 1, 1, 2, 0, 0, 2, 0, 0, 2, 1, 0, 0, 2, 0, 0, 2, 2,\n",
       "       1, 1, 2, 0, 0, 2, 1, 0, 2, 2, 0, 0, 1, 2, 1, 2, 0, 1, 0, 2, 1, 2,\n",
       "       1, 2, 1, 2, 2, 1, 1, 2, 1, 0, 2, 2, 1, 1, 0, 0, 2, 0, 1, 2, 1, 0,\n",
       "       0, 0, 2, 2, 0, 1, 2, 2, 2, 1, 1, 2, 1, 0, 2, 1, 0, 0, 1, 2, 2, 2,\n",
       "       2, 0, 1, 1, 1, 0, 1, 0, 2, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "YpCP7tu9URHL"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "alSOezyrUu6n"
   },
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4rIVBbhbVq8d",
    "outputId": "cf06b989-64fa-4682-95e7-57deb4608113"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "N7IsTZPcVtfU"
   },
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype = torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype = torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype = torch.long)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1Z4ILkFXNZT",
    "outputId": "64b21b6e-5805-451e-9de2-7aa70bbc662c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "iyHKfIf7XPse"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(4, 20)\n",
    "        self.layer2 = nn.Linear(20, 3)\n",
    "        self.output = nn.Softmax()\n",
    "\n",
    "    def forward(self, X):\n",
    "      X = self.layer1(X)\n",
    "      X = self.layer2(X)\n",
    "      X = self.output(X)\n",
    "      return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "mHigzL7BZK1K"
   },
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "jw0kT3sAZi97"
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMQWi1jkZ4oS",
    "outputId": "1975d422-48b4-4f0c-f138-951e7785ef2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.123008370399475\n",
      "Epoch: 1, Loss: 1.0918636322021484\n",
      "Epoch: 2, Loss: 1.0590685606002808\n",
      "Epoch: 3, Loss: 1.0245317220687866\n",
      "Epoch: 4, Loss: 0.9892269968986511\n",
      "Epoch: 5, Loss: 0.9549549221992493\n",
      "Epoch: 6, Loss: 0.9234941005706787\n",
      "Epoch: 7, Loss: 0.8959543108940125\n",
      "Epoch: 8, Loss: 0.8725401163101196\n",
      "Epoch: 9, Loss: 0.852735161781311\n",
      "Epoch: 10, Loss: 0.8357946276664734\n",
      "Epoch: 11, Loss: 0.8211247324943542\n",
      "Epoch: 12, Loss: 0.8083536028862\n",
      "Epoch: 13, Loss: 0.7972614169120789\n",
      "Epoch: 14, Loss: 0.7876908183097839\n",
      "Epoch: 15, Loss: 0.7794843316078186\n",
      "Epoch: 16, Loss: 0.7724552750587463\n",
      "Epoch: 17, Loss: 0.7663868069648743\n",
      "Epoch: 18, Loss: 0.7610504031181335\n",
      "Epoch: 19, Loss: 0.756232500076294\n",
      "Epoch: 20, Loss: 0.7517557144165039\n",
      "Epoch: 21, Loss: 0.747486412525177\n",
      "Epoch: 22, Loss: 0.7433340549468994\n",
      "Epoch: 23, Loss: 0.7392458319664001\n",
      "Epoch: 24, Loss: 0.7351993918418884\n",
      "Epoch: 25, Loss: 0.7311944365501404\n",
      "Epoch: 26, Loss: 0.7272444367408752\n",
      "Epoch: 27, Loss: 0.7233692407608032\n",
      "Epoch: 28, Loss: 0.7195881605148315\n",
      "Epoch: 29, Loss: 0.7159141898155212\n",
      "Epoch: 30, Loss: 0.7123496532440186\n",
      "Epoch: 31, Loss: 0.7088844776153564\n",
      "Epoch: 32, Loss: 0.7054958939552307\n",
      "Epoch: 33, Loss: 0.7021514773368835\n",
      "Epoch: 34, Loss: 0.6988124847412109\n",
      "Epoch: 35, Loss: 0.6954387426376343\n",
      "Epoch: 36, Loss: 0.691994309425354\n",
      "Epoch: 37, Loss: 0.6884509325027466\n",
      "Epoch: 38, Loss: 0.68479323387146\n",
      "Epoch: 39, Loss: 0.6810200810432434\n",
      "Epoch: 40, Loss: 0.6771449446678162\n",
      "Epoch: 41, Loss: 0.6731942892074585\n",
      "Epoch: 42, Loss: 0.6692037582397461\n",
      "Epoch: 43, Loss: 0.6652127504348755\n",
      "Epoch: 44, Loss: 0.6612588167190552\n",
      "Epoch: 45, Loss: 0.6573745012283325\n",
      "Epoch: 46, Loss: 0.653584897518158\n",
      "Epoch: 47, Loss: 0.6499091386795044\n",
      "Epoch: 48, Loss: 0.6463627219200134\n",
      "Epoch: 49, Loss: 0.6429604291915894\n",
      "Epoch: 50, Loss: 0.639718234539032\n",
      "Epoch: 51, Loss: 0.6366533041000366\n",
      "Epoch: 52, Loss: 0.6337824463844299\n",
      "Epoch: 53, Loss: 0.6311179399490356\n",
      "Epoch: 54, Loss: 0.6286645531654358\n",
      "Epoch: 55, Loss: 0.6264156103134155\n",
      "Epoch: 56, Loss: 0.6243533492088318\n",
      "Epoch: 57, Loss: 0.6224507689476013\n",
      "Epoch: 58, Loss: 0.6206775903701782\n",
      "Epoch: 59, Loss: 0.6190050840377808\n",
      "Epoch: 60, Loss: 0.6174110174179077\n",
      "Epoch: 61, Loss: 0.6158809065818787\n",
      "Epoch: 62, Loss: 0.6144064664840698\n",
      "Epoch: 63, Loss: 0.6129837036132812\n",
      "Epoch: 64, Loss: 0.6116097569465637\n",
      "Epoch: 65, Loss: 0.6102825999259949\n",
      "Epoch: 66, Loss: 0.609000563621521\n",
      "Epoch: 67, Loss: 0.6077632308006287\n",
      "Epoch: 68, Loss: 0.6065722703933716\n",
      "Epoch: 69, Loss: 0.6054307222366333\n",
      "Epoch: 70, Loss: 0.6043427586555481\n",
      "Epoch: 71, Loss: 0.603312075138092\n",
      "Epoch: 72, Loss: 0.6023404598236084\n",
      "Epoch: 73, Loss: 0.6014276146888733\n",
      "Epoch: 74, Loss: 0.600570559501648\n",
      "Epoch: 75, Loss: 0.5997653603553772\n",
      "Epoch: 76, Loss: 0.599007248878479\n",
      "Epoch: 77, Loss: 0.5982921123504639\n",
      "Epoch: 78, Loss: 0.5976164937019348\n",
      "Epoch: 79, Loss: 0.5969778299331665\n",
      "Epoch: 80, Loss: 0.5963732600212097\n",
      "Epoch: 81, Loss: 0.5958003401756287\n",
      "Epoch: 82, Loss: 0.5952561497688293\n",
      "Epoch: 83, Loss: 0.5947377681732178\n",
      "Epoch: 84, Loss: 0.5942422151565552\n",
      "Epoch: 85, Loss: 0.5937671661376953\n",
      "Epoch: 86, Loss: 0.5933109521865845\n",
      "Epoch: 87, Loss: 0.5928723812103271\n",
      "Epoch: 88, Loss: 0.5924504995346069\n",
      "Epoch: 89, Loss: 0.5920454859733582\n",
      "Epoch: 90, Loss: 0.5916563272476196\n",
      "Epoch: 91, Loss: 0.5912826061248779\n",
      "Epoch: 92, Loss: 0.5909234881401062\n",
      "Epoch: 93, Loss: 0.5905782580375671\n",
      "Epoch: 94, Loss: 0.5902459621429443\n",
      "Epoch: 95, Loss: 0.5899259448051453\n",
      "Epoch: 96, Loss: 0.5896178483963013\n",
      "Epoch: 97, Loss: 0.589320957660675\n",
      "Epoch: 98, Loss: 0.5890346765518188\n",
      "Epoch: 99, Loss: 0.5887587070465088\n",
      "Epoch: 100, Loss: 0.5884925127029419\n",
      "Epoch: 101, Loss: 0.5882352590560913\n",
      "Epoch: 102, Loss: 0.5879865288734436\n",
      "Epoch: 103, Loss: 0.5877456665039062\n",
      "Epoch: 104, Loss: 0.587512195110321\n",
      "Epoch: 105, Loss: 0.5872859358787537\n",
      "Epoch: 106, Loss: 0.5870662927627563\n",
      "Epoch: 107, Loss: 0.5868532061576843\n",
      "Epoch: 108, Loss: 0.586646318435669\n",
      "Epoch: 109, Loss: 0.5864455699920654\n",
      "Epoch: 110, Loss: 0.586250364780426\n",
      "Epoch: 111, Loss: 0.5860605835914612\n",
      "Epoch: 112, Loss: 0.5858758687973022\n",
      "Epoch: 113, Loss: 0.585696280002594\n",
      "Epoch: 114, Loss: 0.585521399974823\n",
      "Epoch: 115, Loss: 0.5853508710861206\n",
      "Epoch: 116, Loss: 0.5851849913597107\n",
      "Epoch: 117, Loss: 0.5850231051445007\n",
      "Epoch: 118, Loss: 0.5848653316497803\n",
      "Epoch: 119, Loss: 0.5847113728523254\n",
      "Epoch: 120, Loss: 0.5845609903335571\n",
      "Epoch: 121, Loss: 0.5844141244888306\n",
      "Epoch: 122, Loss: 0.5842705368995667\n",
      "Epoch: 123, Loss: 0.5841302871704102\n",
      "Epoch: 124, Loss: 0.5839930772781372\n",
      "Epoch: 125, Loss: 0.5838590264320374\n",
      "Epoch: 126, Loss: 0.5837276577949524\n",
      "Epoch: 127, Loss: 0.5835991501808167\n",
      "Epoch: 128, Loss: 0.5834733247756958\n",
      "Epoch: 129, Loss: 0.5833501815795898\n",
      "Epoch: 130, Loss: 0.5832294821739197\n",
      "Epoch: 131, Loss: 0.5831112265586853\n",
      "Epoch: 132, Loss: 0.5829954147338867\n",
      "Epoch: 133, Loss: 0.5828818678855896\n",
      "Epoch: 134, Loss: 0.582770586013794\n",
      "Epoch: 135, Loss: 0.5826613903045654\n",
      "Epoch: 136, Loss: 0.582554280757904\n",
      "Epoch: 137, Loss: 0.582449197769165\n",
      "Epoch: 138, Loss: 0.5823460817337036\n",
      "Epoch: 139, Loss: 0.5822448134422302\n",
      "Epoch: 140, Loss: 0.5821455717086792\n",
      "Epoch: 141, Loss: 0.5820479989051819\n",
      "Epoch: 142, Loss: 0.5819520354270935\n",
      "Epoch: 143, Loss: 0.5818578600883484\n",
      "Epoch: 144, Loss: 0.5817652940750122\n",
      "Epoch: 145, Loss: 0.5816743969917297\n",
      "Epoch: 146, Loss: 0.5815848708152771\n",
      "Epoch: 147, Loss: 0.5814970135688782\n",
      "Epoch: 148, Loss: 0.5814105868339539\n",
      "Epoch: 149, Loss: 0.5813254117965698\n",
      "Epoch: 150, Loss: 0.5812418460845947\n",
      "Epoch: 151, Loss: 0.5811595320701599\n",
      "Epoch: 152, Loss: 0.5810785293579102\n",
      "Epoch: 153, Loss: 0.5809987783432007\n",
      "Epoch: 154, Loss: 0.580920398235321\n",
      "Epoch: 155, Loss: 0.5808430314064026\n",
      "Epoch: 156, Loss: 0.580767035484314\n",
      "Epoch: 157, Loss: 0.5806921720504761\n",
      "Epoch: 158, Loss: 0.5806183218955994\n",
      "Epoch: 159, Loss: 0.5805456042289734\n",
      "Epoch: 160, Loss: 0.5804741382598877\n",
      "Epoch: 161, Loss: 0.5804035067558289\n",
      "Epoch: 162, Loss: 0.5803340077400208\n",
      "Epoch: 163, Loss: 0.580265462398529\n",
      "Epoch: 164, Loss: 0.5801979899406433\n",
      "Epoch: 165, Loss: 0.5801313519477844\n",
      "Epoch: 166, Loss: 0.5800656676292419\n",
      "Epoch: 167, Loss: 0.5800009369850159\n",
      "Epoch: 168, Loss: 0.5799371004104614\n",
      "Epoch: 169, Loss: 0.5798741579055786\n",
      "Epoch: 170, Loss: 0.5798119902610779\n",
      "Epoch: 171, Loss: 0.5797507762908936\n",
      "Epoch: 172, Loss: 0.5796902775764465\n",
      "Epoch: 173, Loss: 0.5796306133270264\n",
      "Epoch: 174, Loss: 0.5795717835426331\n",
      "Epoch: 175, Loss: 0.579513669013977\n",
      "Epoch: 176, Loss: 0.5794563293457031\n",
      "Epoch: 177, Loss: 0.5793997049331665\n",
      "Epoch: 178, Loss: 0.5793437361717224\n",
      "Epoch: 179, Loss: 0.5792885422706604\n",
      "Epoch: 180, Loss: 0.5792341232299805\n",
      "Epoch: 181, Loss: 0.5791801810264587\n",
      "Epoch: 182, Loss: 0.5791270732879639\n",
      "Epoch: 183, Loss: 0.5790745615959167\n",
      "Epoch: 184, Loss: 0.5790225863456726\n",
      "Epoch: 185, Loss: 0.5789714455604553\n",
      "Epoch: 186, Loss: 0.5789207816123962\n",
      "Epoch: 187, Loss: 0.5788705348968506\n",
      "Epoch: 188, Loss: 0.5788211822509766\n",
      "Epoch: 189, Loss: 0.5787723064422607\n",
      "Epoch: 190, Loss: 0.5787239074707031\n",
      "Epoch: 191, Loss: 0.5786762237548828\n",
      "Epoch: 192, Loss: 0.5786289572715759\n",
      "Epoch: 193, Loss: 0.5785823464393616\n",
      "Epoch: 194, Loss: 0.5785360932350159\n",
      "Epoch: 195, Loss: 0.5784904360771179\n",
      "Epoch: 196, Loss: 0.578445315361023\n",
      "Epoch: 197, Loss: 0.5784006118774414\n",
      "Epoch: 198, Loss: 0.5783564448356628\n",
      "Epoch: 199, Loss: 0.5783127546310425\n",
      "Epoch: 200, Loss: 0.5782695412635803\n",
      "Epoch: 201, Loss: 0.5782266855239868\n",
      "Epoch: 202, Loss: 0.5781843662261963\n",
      "Epoch: 203, Loss: 0.578142523765564\n",
      "Epoch: 204, Loss: 0.5781010985374451\n",
      "Epoch: 205, Loss: 0.5780600309371948\n",
      "Epoch: 206, Loss: 0.578019380569458\n",
      "Epoch: 207, Loss: 0.5779792070388794\n",
      "Epoch: 208, Loss: 0.5779393911361694\n",
      "Epoch: 209, Loss: 0.5779001116752625\n",
      "Epoch: 210, Loss: 0.5778610110282898\n",
      "Epoch: 211, Loss: 0.5778224468231201\n",
      "Epoch: 212, Loss: 0.5777842402458191\n",
      "Epoch: 213, Loss: 0.5777463316917419\n",
      "Epoch: 214, Loss: 0.5777088403701782\n",
      "Epoch: 215, Loss: 0.5776716470718384\n",
      "Epoch: 216, Loss: 0.577634871006012\n",
      "Epoch: 217, Loss: 0.5775984525680542\n",
      "Epoch: 218, Loss: 0.5775623321533203\n",
      "Epoch: 219, Loss: 0.5775266289710999\n",
      "Epoch: 220, Loss: 0.5774911046028137\n",
      "Epoch: 221, Loss: 0.5774558782577515\n",
      "Epoch: 222, Loss: 0.5774211883544922\n",
      "Epoch: 223, Loss: 0.5773866176605225\n",
      "Epoch: 224, Loss: 0.5773523449897766\n",
      "Epoch: 225, Loss: 0.577318549156189\n",
      "Epoch: 226, Loss: 0.5772849321365356\n",
      "Epoch: 227, Loss: 0.5772516131401062\n",
      "Epoch: 228, Loss: 0.5772185921669006\n",
      "Epoch: 229, Loss: 0.5771858096122742\n",
      "Epoch: 230, Loss: 0.5771533846855164\n",
      "Epoch: 231, Loss: 0.5771211981773376\n",
      "Epoch: 232, Loss: 0.5770893096923828\n",
      "Epoch: 233, Loss: 0.5770576596260071\n",
      "Epoch: 234, Loss: 0.5770261883735657\n",
      "Epoch: 235, Loss: 0.5769950747489929\n",
      "Epoch: 236, Loss: 0.5769641995429993\n",
      "Epoch: 237, Loss: 0.5769335627555847\n",
      "Epoch: 238, Loss: 0.576903223991394\n",
      "Epoch: 239, Loss: 0.5768730044364929\n",
      "Epoch: 240, Loss: 0.5768430829048157\n",
      "Epoch: 241, Loss: 0.5768133401870728\n",
      "Epoch: 242, Loss: 0.5767839550971985\n",
      "Epoch: 243, Loss: 0.576754629611969\n",
      "Epoch: 244, Loss: 0.5767256021499634\n",
      "Epoch: 245, Loss: 0.5766968131065369\n",
      "Epoch: 246, Loss: 0.5766682028770447\n",
      "Epoch: 247, Loss: 0.5766398906707764\n",
      "Epoch: 248, Loss: 0.5766116976737976\n",
      "Epoch: 249, Loss: 0.5765836834907532\n",
      "Epoch: 250, Loss: 0.5765559077262878\n",
      "Epoch: 251, Loss: 0.5765283107757568\n",
      "Epoch: 252, Loss: 0.5765009522438049\n",
      "Epoch: 253, Loss: 0.5764738321304321\n",
      "Epoch: 254, Loss: 0.5764468312263489\n",
      "Epoch: 255, Loss: 0.5764200091362\n",
      "Epoch: 256, Loss: 0.5763933658599854\n",
      "Epoch: 257, Loss: 0.5763667821884155\n",
      "Epoch: 258, Loss: 0.5763406157493591\n",
      "Epoch: 259, Loss: 0.5763145089149475\n",
      "Epoch: 260, Loss: 0.5762885808944702\n",
      "Epoch: 261, Loss: 0.5762627720832825\n",
      "Epoch: 262, Loss: 0.5762373805046082\n",
      "Epoch: 263, Loss: 0.5762117505073547\n",
      "Epoch: 264, Loss: 0.5761865377426147\n",
      "Epoch: 265, Loss: 0.5761614441871643\n",
      "Epoch: 266, Loss: 0.576136589050293\n",
      "Epoch: 267, Loss: 0.5761116743087769\n",
      "Epoch: 268, Loss: 0.5760869979858398\n",
      "Epoch: 269, Loss: 0.5760625004768372\n",
      "Epoch: 270, Loss: 0.5760382413864136\n",
      "Epoch: 271, Loss: 0.57601398229599\n",
      "Epoch: 272, Loss: 0.5759899616241455\n",
      "Epoch: 273, Loss: 0.5759660005569458\n",
      "Epoch: 274, Loss: 0.5759422779083252\n",
      "Epoch: 275, Loss: 0.5759185552597046\n",
      "Epoch: 276, Loss: 0.5758951306343079\n",
      "Epoch: 277, Loss: 0.5758717060089111\n",
      "Epoch: 278, Loss: 0.575848400592804\n",
      "Epoch: 279, Loss: 0.5758252739906311\n",
      "Epoch: 280, Loss: 0.5758022665977478\n",
      "Epoch: 281, Loss: 0.575779378414154\n",
      "Epoch: 282, Loss: 0.5757566690444946\n",
      "Epoch: 283, Loss: 0.57573401927948\n",
      "Epoch: 284, Loss: 0.5757115483283997\n",
      "Epoch: 285, Loss: 0.5756890773773193\n",
      "Epoch: 286, Loss: 0.5756667852401733\n",
      "Epoch: 287, Loss: 0.5756446123123169\n",
      "Epoch: 288, Loss: 0.5756226181983948\n",
      "Epoch: 289, Loss: 0.5756006240844727\n",
      "Epoch: 290, Loss: 0.5755788087844849\n",
      "Epoch: 291, Loss: 0.5755569934844971\n",
      "Epoch: 292, Loss: 0.5755354166030884\n",
      "Epoch: 293, Loss: 0.5755138397216797\n",
      "Epoch: 294, Loss: 0.5754923224449158\n",
      "Epoch: 295, Loss: 0.5754711031913757\n",
      "Epoch: 296, Loss: 0.5754498839378357\n",
      "Epoch: 297, Loss: 0.5754287242889404\n",
      "Epoch: 298, Loss: 0.5754077434539795\n",
      "Epoch: 299, Loss: 0.5753867626190186\n",
      "Epoch: 300, Loss: 0.5753658413887024\n",
      "Epoch: 301, Loss: 0.5753450989723206\n",
      "Epoch: 302, Loss: 0.5753244161605835\n",
      "Epoch: 303, Loss: 0.5753039121627808\n",
      "Epoch: 304, Loss: 0.5752833485603333\n",
      "Epoch: 305, Loss: 0.5752629637718201\n",
      "Epoch: 306, Loss: 0.5752426385879517\n",
      "Epoch: 307, Loss: 0.575222373008728\n",
      "Epoch: 308, Loss: 0.5752021670341492\n",
      "Epoch: 309, Loss: 0.5751821398735046\n",
      "Epoch: 310, Loss: 0.5751621127128601\n",
      "Epoch: 311, Loss: 0.5751421451568604\n",
      "Epoch: 312, Loss: 0.5751222968101501\n",
      "Epoch: 313, Loss: 0.5751026272773743\n",
      "Epoch: 314, Loss: 0.5750828981399536\n",
      "Epoch: 315, Loss: 0.5750632882118225\n",
      "Epoch: 316, Loss: 0.5750436782836914\n",
      "Epoch: 317, Loss: 0.5750243067741394\n",
      "Epoch: 318, Loss: 0.5750048160552979\n",
      "Epoch: 319, Loss: 0.5749855041503906\n",
      "Epoch: 320, Loss: 0.5749662518501282\n",
      "Epoch: 321, Loss: 0.5749470591545105\n",
      "Epoch: 322, Loss: 0.5749279260635376\n",
      "Epoch: 323, Loss: 0.5749088525772095\n",
      "Epoch: 324, Loss: 0.5748898983001709\n",
      "Epoch: 325, Loss: 0.5748708844184875\n",
      "Epoch: 326, Loss: 0.5748519897460938\n",
      "Epoch: 327, Loss: 0.5748331546783447\n",
      "Epoch: 328, Loss: 0.5748143792152405\n",
      "Epoch: 329, Loss: 0.574795663356781\n",
      "Epoch: 330, Loss: 0.5747770071029663\n",
      "Epoch: 331, Loss: 0.5747584104537964\n",
      "Epoch: 332, Loss: 0.5747400522232056\n",
      "Epoch: 333, Loss: 0.5747213959693909\n",
      "Epoch: 334, Loss: 0.5747030973434448\n",
      "Epoch: 335, Loss: 0.574684739112854\n",
      "Epoch: 336, Loss: 0.5746663212776184\n",
      "Epoch: 337, Loss: 0.5746481418609619\n",
      "Epoch: 338, Loss: 0.5746299624443054\n",
      "Epoch: 339, Loss: 0.5746117830276489\n",
      "Epoch: 340, Loss: 0.5745936632156372\n",
      "Epoch: 341, Loss: 0.574575662612915\n",
      "Epoch: 342, Loss: 0.5745576620101929\n",
      "Epoch: 343, Loss: 0.5745397806167603\n",
      "Epoch: 344, Loss: 0.5745218396186829\n",
      "Epoch: 345, Loss: 0.5745038986206055\n",
      "Epoch: 346, Loss: 0.5744861364364624\n",
      "Epoch: 347, Loss: 0.5744684338569641\n",
      "Epoch: 348, Loss: 0.574450671672821\n",
      "Epoch: 349, Loss: 0.5744329690933228\n",
      "Epoch: 350, Loss: 0.5744152665138245\n",
      "Epoch: 351, Loss: 0.5743978023529053\n",
      "Epoch: 352, Loss: 0.5743801593780518\n",
      "Epoch: 353, Loss: 0.5743626952171326\n",
      "Epoch: 354, Loss: 0.5743453502655029\n",
      "Epoch: 355, Loss: 0.574327826499939\n",
      "Epoch: 356, Loss: 0.5743104219436646\n",
      "Epoch: 357, Loss: 0.5742931365966797\n",
      "Epoch: 358, Loss: 0.5742758512496948\n",
      "Epoch: 359, Loss: 0.5742586255073547\n",
      "Epoch: 360, Loss: 0.5742413401603699\n",
      "Epoch: 361, Loss: 0.5742242336273193\n",
      "Epoch: 362, Loss: 0.574207067489624\n",
      "Epoch: 363, Loss: 0.5741899013519287\n",
      "Epoch: 364, Loss: 0.5741729140281677\n",
      "Epoch: 365, Loss: 0.5741558074951172\n",
      "Epoch: 366, Loss: 0.5741388201713562\n",
      "Epoch: 367, Loss: 0.5741220116615295\n",
      "Epoch: 368, Loss: 0.5741050839424133\n",
      "Epoch: 369, Loss: 0.5740880966186523\n",
      "Epoch: 370, Loss: 0.5740712881088257\n",
      "Epoch: 371, Loss: 0.574054479598999\n",
      "Epoch: 372, Loss: 0.5740376710891724\n",
      "Epoch: 373, Loss: 0.5740209221839905\n",
      "Epoch: 374, Loss: 0.5740042328834534\n",
      "Epoch: 375, Loss: 0.5739875435829163\n",
      "Epoch: 376, Loss: 0.5739708542823792\n",
      "Epoch: 377, Loss: 0.5739542841911316\n",
      "Epoch: 378, Loss: 0.5739375948905945\n",
      "Epoch: 379, Loss: 0.5739210844039917\n",
      "Epoch: 380, Loss: 0.5739044547080994\n",
      "Epoch: 381, Loss: 0.5738880038261414\n",
      "Epoch: 382, Loss: 0.5738715529441833\n",
      "Epoch: 383, Loss: 0.5738551616668701\n",
      "Epoch: 384, Loss: 0.5738387703895569\n",
      "Epoch: 385, Loss: 0.5738223195075989\n",
      "Epoch: 386, Loss: 0.5738059878349304\n",
      "Epoch: 387, Loss: 0.5737897157669067\n",
      "Epoch: 388, Loss: 0.5737734436988831\n",
      "Epoch: 389, Loss: 0.5737571716308594\n",
      "Epoch: 390, Loss: 0.5737409591674805\n",
      "Epoch: 391, Loss: 0.5737247467041016\n",
      "Epoch: 392, Loss: 0.5737085342407227\n",
      "Epoch: 393, Loss: 0.5736924409866333\n",
      "Epoch: 394, Loss: 0.5736762285232544\n",
      "Epoch: 395, Loss: 0.5736601948738098\n",
      "Epoch: 396, Loss: 0.5736441016197205\n",
      "Epoch: 397, Loss: 0.5736281275749207\n",
      "Epoch: 398, Loss: 0.5736120939254761\n",
      "Epoch: 399, Loss: 0.5735961198806763\n",
      "Epoch: 400, Loss: 0.5735801458358765\n",
      "Epoch: 401, Loss: 0.5735642910003662\n",
      "Epoch: 402, Loss: 0.5735483765602112\n",
      "Epoch: 403, Loss: 0.5735324621200562\n",
      "Epoch: 404, Loss: 0.5735166072845459\n",
      "Epoch: 405, Loss: 0.5735007524490356\n",
      "Epoch: 406, Loss: 0.5734850168228149\n",
      "Epoch: 407, Loss: 0.5734691619873047\n",
      "Epoch: 408, Loss: 0.5734534859657288\n",
      "Epoch: 409, Loss: 0.5734377503395081\n",
      "Epoch: 410, Loss: 0.5734220743179321\n",
      "Epoch: 411, Loss: 0.5734062790870667\n",
      "Epoch: 412, Loss: 0.5733907222747803\n",
      "Epoch: 413, Loss: 0.5733751058578491\n",
      "Epoch: 414, Loss: 0.573359489440918\n",
      "Epoch: 415, Loss: 0.5733439326286316\n",
      "Epoch: 416, Loss: 0.5733283758163452\n",
      "Epoch: 417, Loss: 0.5733127593994141\n",
      "Epoch: 418, Loss: 0.5732972025871277\n",
      "Epoch: 419, Loss: 0.5732816457748413\n",
      "Epoch: 420, Loss: 0.5732662677764893\n",
      "Epoch: 421, Loss: 0.5732508301734924\n",
      "Epoch: 422, Loss: 0.5732355117797852\n",
      "Epoch: 423, Loss: 0.5732200145721436\n",
      "Epoch: 424, Loss: 0.5732046961784363\n",
      "Epoch: 425, Loss: 0.5731893181800842\n",
      "Epoch: 426, Loss: 0.5731740593910217\n",
      "Epoch: 427, Loss: 0.5731588006019592\n",
      "Epoch: 428, Loss: 0.5731434226036072\n",
      "Epoch: 429, Loss: 0.5731281638145447\n",
      "Epoch: 430, Loss: 0.5731130242347717\n",
      "Epoch: 431, Loss: 0.5730977654457092\n",
      "Epoch: 432, Loss: 0.5730826258659363\n",
      "Epoch: 433, Loss: 0.5730674266815186\n",
      "Epoch: 434, Loss: 0.5730522871017456\n",
      "Epoch: 435, Loss: 0.5730372071266174\n",
      "Epoch: 436, Loss: 0.5730220079421997\n",
      "Epoch: 437, Loss: 0.5730069875717163\n",
      "Epoch: 438, Loss: 0.5729920268058777\n",
      "Epoch: 439, Loss: 0.5729769468307495\n",
      "Epoch: 440, Loss: 0.5729619860649109\n",
      "Epoch: 441, Loss: 0.5729469656944275\n",
      "Epoch: 442, Loss: 0.5729320049285889\n",
      "Epoch: 443, Loss: 0.5729170441627502\n",
      "Epoch: 444, Loss: 0.5729021430015564\n",
      "Epoch: 445, Loss: 0.5728872418403625\n",
      "Epoch: 446, Loss: 0.5728724002838135\n",
      "Epoch: 447, Loss: 0.5728576183319092\n",
      "Epoch: 448, Loss: 0.5728427171707153\n",
      "Epoch: 449, Loss: 0.5728278756141663\n",
      "Epoch: 450, Loss: 0.572813093662262\n",
      "Epoch: 451, Loss: 0.5727983713150024\n",
      "Epoch: 452, Loss: 0.5727835893630981\n",
      "Epoch: 453, Loss: 0.5727688670158386\n",
      "Epoch: 454, Loss: 0.5727540850639343\n",
      "Epoch: 455, Loss: 0.5727395415306091\n",
      "Epoch: 456, Loss: 0.5727248787879944\n",
      "Epoch: 457, Loss: 0.5727102160453796\n",
      "Epoch: 458, Loss: 0.5726955533027649\n",
      "Epoch: 459, Loss: 0.5726810693740845\n",
      "Epoch: 460, Loss: 0.5726664066314697\n",
      "Epoch: 461, Loss: 0.5726518630981445\n",
      "Epoch: 462, Loss: 0.5726373791694641\n",
      "Epoch: 463, Loss: 0.5726228356361389\n",
      "Epoch: 464, Loss: 0.5726082921028137\n",
      "Epoch: 465, Loss: 0.5725938081741333\n",
      "Epoch: 466, Loss: 0.5725793838500977\n",
      "Epoch: 467, Loss: 0.572564959526062\n",
      "Epoch: 468, Loss: 0.5725505352020264\n",
      "Epoch: 469, Loss: 0.5725362300872803\n",
      "Epoch: 470, Loss: 0.5725218057632446\n",
      "Epoch: 471, Loss: 0.5725074410438538\n",
      "Epoch: 472, Loss: 0.5724931359291077\n",
      "Epoch: 473, Loss: 0.5724788308143616\n",
      "Epoch: 474, Loss: 0.5724644064903259\n",
      "Epoch: 475, Loss: 0.5724502205848694\n",
      "Epoch: 476, Loss: 0.5724359750747681\n",
      "Epoch: 477, Loss: 0.572421669960022\n",
      "Epoch: 478, Loss: 0.5724074244499207\n",
      "Epoch: 479, Loss: 0.5723931789398193\n",
      "Epoch: 480, Loss: 0.5723790526390076\n",
      "Epoch: 481, Loss: 0.5723649263381958\n",
      "Epoch: 482, Loss: 0.5723507404327393\n",
      "Epoch: 483, Loss: 0.5723366141319275\n",
      "Epoch: 484, Loss: 0.5723225474357605\n",
      "Epoch: 485, Loss: 0.5723084211349487\n",
      "Epoch: 486, Loss: 0.5722943544387817\n",
      "Epoch: 487, Loss: 0.5722802877426147\n",
      "Epoch: 488, Loss: 0.5722662806510925\n",
      "Epoch: 489, Loss: 0.5722522735595703\n",
      "Epoch: 490, Loss: 0.5722382664680481\n",
      "Epoch: 491, Loss: 0.5722243189811707\n",
      "Epoch: 492, Loss: 0.5722103714942932\n",
      "Epoch: 493, Loss: 0.5721964240074158\n",
      "Epoch: 494, Loss: 0.5721824765205383\n",
      "Epoch: 495, Loss: 0.5721685886383057\n",
      "Epoch: 496, Loss: 0.5721547603607178\n",
      "Epoch: 497, Loss: 0.5721408724784851\n",
      "Epoch: 498, Loss: 0.5721270442008972\n",
      "Epoch: 499, Loss: 0.5721131563186646\n",
      "Epoch: 500, Loss: 0.5720993876457214\n",
      "Epoch: 501, Loss: 0.5720855593681335\n",
      "Epoch: 502, Loss: 0.5720717906951904\n",
      "Epoch: 503, Loss: 0.5720579624176025\n",
      "Epoch: 504, Loss: 0.572044312953949\n",
      "Epoch: 505, Loss: 0.5720304846763611\n",
      "Epoch: 506, Loss: 0.5720168352127075\n",
      "Epoch: 507, Loss: 0.572003185749054\n",
      "Epoch: 508, Loss: 0.5719894170761108\n",
      "Epoch: 509, Loss: 0.571975827217102\n",
      "Epoch: 510, Loss: 0.5719622373580933\n",
      "Epoch: 511, Loss: 0.5719484686851501\n",
      "Epoch: 512, Loss: 0.5719348788261414\n",
      "Epoch: 513, Loss: 0.5719212889671326\n",
      "Epoch: 514, Loss: 0.5719076991081238\n",
      "Epoch: 515, Loss: 0.571894109249115\n",
      "Epoch: 516, Loss: 0.571880578994751\n",
      "Epoch: 517, Loss: 0.571867048740387\n",
      "Epoch: 518, Loss: 0.571853518486023\n",
      "Epoch: 519, Loss: 0.5718400478363037\n",
      "Epoch: 520, Loss: 0.5718265771865845\n",
      "Epoch: 521, Loss: 0.5718130469322205\n",
      "Epoch: 522, Loss: 0.5717995762825012\n",
      "Epoch: 523, Loss: 0.5717861652374268\n",
      "Epoch: 524, Loss: 0.5717727541923523\n",
      "Epoch: 525, Loss: 0.5717594027519226\n",
      "Epoch: 526, Loss: 0.5717459917068481\n",
      "Epoch: 527, Loss: 0.5717325806617737\n",
      "Epoch: 528, Loss: 0.5717191696166992\n",
      "Epoch: 529, Loss: 0.5717058777809143\n",
      "Epoch: 530, Loss: 0.5716925263404846\n",
      "Epoch: 531, Loss: 0.5716792345046997\n",
      "Epoch: 532, Loss: 0.57166588306427\n",
      "Epoch: 533, Loss: 0.5716525912284851\n",
      "Epoch: 534, Loss: 0.571639358997345\n",
      "Epoch: 535, Loss: 0.5716260075569153\n",
      "Epoch: 536, Loss: 0.5716127157211304\n",
      "Epoch: 537, Loss: 0.5715996026992798\n",
      "Epoch: 538, Loss: 0.5715863108634949\n",
      "Epoch: 539, Loss: 0.57157301902771\n",
      "Epoch: 540, Loss: 0.5715599060058594\n",
      "Epoch: 541, Loss: 0.571546733379364\n",
      "Epoch: 542, Loss: 0.5715335011482239\n",
      "Epoch: 543, Loss: 0.5715203881263733\n",
      "Epoch: 544, Loss: 0.5715072154998779\n",
      "Epoch: 545, Loss: 0.5714941024780273\n",
      "Epoch: 546, Loss: 0.571480929851532\n",
      "Epoch: 547, Loss: 0.571467936038971\n",
      "Epoch: 548, Loss: 0.5714547634124756\n",
      "Epoch: 549, Loss: 0.571441650390625\n",
      "Epoch: 550, Loss: 0.571428656578064\n",
      "Epoch: 551, Loss: 0.5714156031608582\n",
      "Epoch: 552, Loss: 0.5714025497436523\n",
      "Epoch: 553, Loss: 0.5713894963264465\n",
      "Epoch: 554, Loss: 0.5713765621185303\n",
      "Epoch: 555, Loss: 0.5713634490966797\n",
      "Epoch: 556, Loss: 0.5713504552841187\n",
      "Epoch: 557, Loss: 0.5713375210762024\n",
      "Epoch: 558, Loss: 0.5713244676589966\n",
      "Epoch: 559, Loss: 0.5713115334510803\n",
      "Epoch: 560, Loss: 0.5712985992431641\n",
      "Epoch: 561, Loss: 0.5712856650352478\n",
      "Epoch: 562, Loss: 0.5712727308273315\n",
      "Epoch: 563, Loss: 0.5712597370147705\n",
      "Epoch: 564, Loss: 0.5712469816207886\n",
      "Epoch: 565, Loss: 0.5712340474128723\n",
      "Epoch: 566, Loss: 0.5712211728096008\n",
      "Epoch: 567, Loss: 0.5712082982063293\n",
      "Epoch: 568, Loss: 0.5711954236030579\n",
      "Epoch: 569, Loss: 0.5711825489997864\n",
      "Epoch: 570, Loss: 0.5711697340011597\n",
      "Epoch: 571, Loss: 0.5711568593978882\n",
      "Epoch: 572, Loss: 0.5711441040039062\n",
      "Epoch: 573, Loss: 0.5711312890052795\n",
      "Epoch: 574, Loss: 0.5711184740066528\n",
      "Epoch: 575, Loss: 0.5711057186126709\n",
      "Epoch: 576, Loss: 0.5710929036140442\n",
      "Epoch: 577, Loss: 0.5710801482200623\n",
      "Epoch: 578, Loss: 0.5710674524307251\n",
      "Epoch: 579, Loss: 0.5710546374320984\n",
      "Epoch: 580, Loss: 0.5710419416427612\n",
      "Epoch: 581, Loss: 0.5710292458534241\n",
      "Epoch: 582, Loss: 0.5710165500640869\n",
      "Epoch: 583, Loss: 0.5710038542747498\n",
      "Epoch: 584, Loss: 0.5709910988807678\n",
      "Epoch: 585, Loss: 0.5709784626960754\n",
      "Epoch: 586, Loss: 0.5709657669067383\n",
      "Epoch: 587, Loss: 0.5709531307220459\n",
      "Epoch: 588, Loss: 0.5709405541419983\n",
      "Epoch: 589, Loss: 0.5709278583526611\n",
      "Epoch: 590, Loss: 0.5709152817726135\n",
      "Epoch: 591, Loss: 0.5709027051925659\n",
      "Epoch: 592, Loss: 0.5708900094032288\n",
      "Epoch: 593, Loss: 0.5708773732185364\n",
      "Epoch: 594, Loss: 0.5708647966384888\n",
      "Epoch: 595, Loss: 0.5708522200584412\n",
      "Epoch: 596, Loss: 0.5708396434783936\n",
      "Epoch: 597, Loss: 0.5708271265029907\n",
      "Epoch: 598, Loss: 0.5708145499229431\n",
      "Epoch: 599, Loss: 0.5708019733428955\n",
      "Epoch: 600, Loss: 0.5707894563674927\n",
      "Epoch: 601, Loss: 0.5707769393920898\n",
      "Epoch: 602, Loss: 0.5707643628120422\n",
      "Epoch: 603, Loss: 0.570751965045929\n",
      "Epoch: 604, Loss: 0.5707394480705261\n",
      "Epoch: 605, Loss: 0.5707269310951233\n",
      "Epoch: 606, Loss: 0.5707144141197205\n",
      "Epoch: 607, Loss: 0.5707020163536072\n",
      "Epoch: 608, Loss: 0.5706894397735596\n",
      "Epoch: 609, Loss: 0.5706770420074463\n",
      "Epoch: 610, Loss: 0.5706645846366882\n",
      "Epoch: 611, Loss: 0.5706521272659302\n",
      "Epoch: 612, Loss: 0.5706397294998169\n",
      "Epoch: 613, Loss: 0.5706272721290588\n",
      "Epoch: 614, Loss: 0.5706149339675903\n",
      "Epoch: 615, Loss: 0.5706024765968323\n",
      "Epoch: 616, Loss: 0.570590078830719\n",
      "Epoch: 617, Loss: 0.5705776810646057\n",
      "Epoch: 618, Loss: 0.5705653429031372\n",
      "Epoch: 619, Loss: 0.5705528855323792\n",
      "Epoch: 620, Loss: 0.5705405473709106\n",
      "Epoch: 621, Loss: 0.5705282688140869\n",
      "Epoch: 622, Loss: 0.5705159306526184\n",
      "Epoch: 623, Loss: 0.5705035328865051\n",
      "Epoch: 624, Loss: 0.5704911947250366\n",
      "Epoch: 625, Loss: 0.5704788565635681\n",
      "Epoch: 626, Loss: 0.5704666972160339\n",
      "Epoch: 627, Loss: 0.5704542994499207\n",
      "Epoch: 628, Loss: 0.5704420208930969\n",
      "Epoch: 629, Loss: 0.5704297423362732\n",
      "Epoch: 630, Loss: 0.5704174041748047\n",
      "Epoch: 631, Loss: 0.5704051852226257\n",
      "Epoch: 632, Loss: 0.5703928470611572\n",
      "Epoch: 633, Loss: 0.5703806281089783\n",
      "Epoch: 634, Loss: 0.5703684687614441\n",
      "Epoch: 635, Loss: 0.5703561305999756\n",
      "Epoch: 636, Loss: 0.5703438520431519\n",
      "Epoch: 637, Loss: 0.5703317523002625\n",
      "Epoch: 638, Loss: 0.570319414138794\n",
      "Epoch: 639, Loss: 0.5703073143959045\n",
      "Epoch: 640, Loss: 0.5702950954437256\n",
      "Epoch: 641, Loss: 0.5702829360961914\n",
      "Epoch: 642, Loss: 0.5702707171440125\n",
      "Epoch: 643, Loss: 0.5702585577964783\n",
      "Epoch: 644, Loss: 0.5702463984489441\n",
      "Epoch: 645, Loss: 0.5702341794967651\n",
      "Epoch: 646, Loss: 0.5702220797538757\n",
      "Epoch: 647, Loss: 0.5702098608016968\n",
      "Epoch: 648, Loss: 0.5701977610588074\n",
      "Epoch: 649, Loss: 0.5701856017112732\n",
      "Epoch: 650, Loss: 0.570173442363739\n",
      "Epoch: 651, Loss: 0.5701614022254944\n",
      "Epoch: 652, Loss: 0.570149302482605\n",
      "Epoch: 653, Loss: 0.5701372027397156\n",
      "Epoch: 654, Loss: 0.5701250433921814\n",
      "Epoch: 655, Loss: 0.5701130032539368\n",
      "Epoch: 656, Loss: 0.5701009631156921\n",
      "Epoch: 657, Loss: 0.5700889229774475\n",
      "Epoch: 658, Loss: 0.5700767636299133\n",
      "Epoch: 659, Loss: 0.5700646638870239\n",
      "Epoch: 660, Loss: 0.5700526833534241\n",
      "Epoch: 661, Loss: 0.5700406432151794\n",
      "Epoch: 662, Loss: 0.57002854347229\n",
      "Epoch: 663, Loss: 0.5700165629386902\n",
      "Epoch: 664, Loss: 0.5700045824050903\n",
      "Epoch: 665, Loss: 0.5699924826622009\n",
      "Epoch: 666, Loss: 0.5699804425239563\n",
      "Epoch: 667, Loss: 0.5699685215950012\n",
      "Epoch: 668, Loss: 0.5699565410614014\n",
      "Epoch: 669, Loss: 0.5699445009231567\n",
      "Epoch: 670, Loss: 0.5699325799942017\n",
      "Epoch: 671, Loss: 0.5699205994606018\n",
      "Epoch: 672, Loss: 0.5699085593223572\n",
      "Epoch: 673, Loss: 0.5698966979980469\n",
      "Epoch: 674, Loss: 0.569884717464447\n",
      "Epoch: 675, Loss: 0.5698727965354919\n",
      "Epoch: 676, Loss: 0.5698608160018921\n",
      "Epoch: 677, Loss: 0.5698489546775818\n",
      "Epoch: 678, Loss: 0.5698370337486267\n",
      "Epoch: 679, Loss: 0.5698251724243164\n",
      "Epoch: 680, Loss: 0.5698133111000061\n",
      "Epoch: 681, Loss: 0.5698013305664062\n",
      "Epoch: 682, Loss: 0.5697895288467407\n",
      "Epoch: 683, Loss: 0.5697776079177856\n",
      "Epoch: 684, Loss: 0.5697657465934753\n",
      "Epoch: 685, Loss: 0.5697538256645203\n",
      "Epoch: 686, Loss: 0.56974196434021\n",
      "Epoch: 687, Loss: 0.5697301626205444\n",
      "Epoch: 688, Loss: 0.5697183012962341\n",
      "Epoch: 689, Loss: 0.569706380367279\n",
      "Epoch: 690, Loss: 0.5696946382522583\n",
      "Epoch: 691, Loss: 0.5696828961372375\n",
      "Epoch: 692, Loss: 0.5696710348129272\n",
      "Epoch: 693, Loss: 0.5696592330932617\n",
      "Epoch: 694, Loss: 0.5696474313735962\n",
      "Epoch: 695, Loss: 0.5696356296539307\n",
      "Epoch: 696, Loss: 0.5696238875389099\n",
      "Epoch: 697, Loss: 0.5696121454238892\n",
      "Epoch: 698, Loss: 0.5696002840995789\n",
      "Epoch: 699, Loss: 0.5695885419845581\n",
      "Epoch: 700, Loss: 0.5695768594741821\n",
      "Epoch: 701, Loss: 0.5695650577545166\n",
      "Epoch: 702, Loss: 0.5695533752441406\n",
      "Epoch: 703, Loss: 0.5695416331291199\n",
      "Epoch: 704, Loss: 0.5695298910140991\n",
      "Epoch: 705, Loss: 0.5695182085037231\n",
      "Epoch: 706, Loss: 0.5695065259933472\n",
      "Epoch: 707, Loss: 0.5694948434829712\n",
      "Epoch: 708, Loss: 0.5694831013679504\n",
      "Epoch: 709, Loss: 0.5694714784622192\n",
      "Epoch: 710, Loss: 0.5694597363471985\n",
      "Epoch: 711, Loss: 0.5694481730461121\n",
      "Epoch: 712, Loss: 0.5694364309310913\n",
      "Epoch: 713, Loss: 0.5694247484207153\n",
      "Epoch: 714, Loss: 0.5694131255149841\n",
      "Epoch: 715, Loss: 0.5694015026092529\n",
      "Epoch: 716, Loss: 0.5693899393081665\n",
      "Epoch: 717, Loss: 0.5693781971931458\n",
      "Epoch: 718, Loss: 0.5693666338920593\n",
      "Epoch: 719, Loss: 0.5693550705909729\n",
      "Epoch: 720, Loss: 0.5693434476852417\n",
      "Epoch: 721, Loss: 0.5693318843841553\n",
      "Epoch: 722, Loss: 0.5693203210830688\n",
      "Epoch: 723, Loss: 0.5693086385726929\n",
      "Epoch: 724, Loss: 0.5692970752716064\n",
      "Epoch: 725, Loss: 0.56928551197052\n",
      "Epoch: 726, Loss: 0.5692740082740784\n",
      "Epoch: 727, Loss: 0.5692624449729919\n",
      "Epoch: 728, Loss: 0.5692509412765503\n",
      "Epoch: 729, Loss: 0.5692394971847534\n",
      "Epoch: 730, Loss: 0.569227933883667\n",
      "Epoch: 731, Loss: 0.5692163705825806\n",
      "Epoch: 732, Loss: 0.5692049264907837\n",
      "Epoch: 733, Loss: 0.569193422794342\n",
      "Epoch: 734, Loss: 0.5691818594932556\n",
      "Epoch: 735, Loss: 0.569170355796814\n",
      "Epoch: 736, Loss: 0.5691589713096619\n",
      "Epoch: 737, Loss: 0.5691474676132202\n",
      "Epoch: 738, Loss: 0.5691360235214233\n",
      "Epoch: 739, Loss: 0.5691245794296265\n",
      "Epoch: 740, Loss: 0.5691131353378296\n",
      "Epoch: 741, Loss: 0.5691016912460327\n",
      "Epoch: 742, Loss: 0.5690903067588806\n",
      "Epoch: 743, Loss: 0.5690789818763733\n",
      "Epoch: 744, Loss: 0.5690675377845764\n",
      "Epoch: 745, Loss: 0.5690561532974243\n",
      "Epoch: 746, Loss: 0.5690447688102722\n",
      "Epoch: 747, Loss: 0.5690333843231201\n",
      "Epoch: 748, Loss: 0.569021999835968\n",
      "Epoch: 749, Loss: 0.5690106749534607\n",
      "Epoch: 750, Loss: 0.5689992308616638\n",
      "Epoch: 751, Loss: 0.5689879059791565\n",
      "Epoch: 752, Loss: 0.5689765810966492\n",
      "Epoch: 753, Loss: 0.5689652562141418\n",
      "Epoch: 754, Loss: 0.5689539313316345\n",
      "Epoch: 755, Loss: 0.568942666053772\n",
      "Epoch: 756, Loss: 0.5689314007759094\n",
      "Epoch: 757, Loss: 0.5689200162887573\n",
      "Epoch: 758, Loss: 0.5689087510108948\n",
      "Epoch: 759, Loss: 0.5688974857330322\n",
      "Epoch: 760, Loss: 0.5688862204551697\n",
      "Epoch: 761, Loss: 0.5688750147819519\n",
      "Epoch: 762, Loss: 0.5688637495040894\n",
      "Epoch: 763, Loss: 0.5688524842262268\n",
      "Epoch: 764, Loss: 0.5688412189483643\n",
      "Epoch: 765, Loss: 0.5688299536705017\n",
      "Epoch: 766, Loss: 0.5688188076019287\n",
      "Epoch: 767, Loss: 0.5688075423240662\n",
      "Epoch: 768, Loss: 0.5687963366508484\n",
      "Epoch: 769, Loss: 0.5687851309776306\n",
      "Epoch: 770, Loss: 0.5687740445137024\n",
      "Epoch: 771, Loss: 0.5687627792358398\n",
      "Epoch: 772, Loss: 0.5687516331672668\n",
      "Epoch: 773, Loss: 0.5687405467033386\n",
      "Epoch: 774, Loss: 0.5687294006347656\n",
      "Epoch: 775, Loss: 0.5687181949615479\n",
      "Epoch: 776, Loss: 0.5687071084976196\n",
      "Epoch: 777, Loss: 0.5686959624290466\n",
      "Epoch: 778, Loss: 0.5686848759651184\n",
      "Epoch: 779, Loss: 0.5686737895011902\n",
      "Epoch: 780, Loss: 0.5686626434326172\n",
      "Epoch: 781, Loss: 0.568651556968689\n",
      "Epoch: 782, Loss: 0.5686405301094055\n",
      "Epoch: 783, Loss: 0.5686293840408325\n",
      "Epoch: 784, Loss: 0.5686183571815491\n",
      "Epoch: 785, Loss: 0.5686072707176208\n",
      "Epoch: 786, Loss: 0.5685961842536926\n",
      "Epoch: 787, Loss: 0.568585216999054\n",
      "Epoch: 788, Loss: 0.5685741901397705\n",
      "Epoch: 789, Loss: 0.5685631632804871\n",
      "Epoch: 790, Loss: 0.5685521364212036\n",
      "Epoch: 791, Loss: 0.5685412287712097\n",
      "Epoch: 792, Loss: 0.5685302019119263\n",
      "Epoch: 793, Loss: 0.5685192346572876\n",
      "Epoch: 794, Loss: 0.5685082674026489\n",
      "Epoch: 795, Loss: 0.5684973001480103\n",
      "Epoch: 796, Loss: 0.5684862732887268\n",
      "Epoch: 797, Loss: 0.5684753656387329\n",
      "Epoch: 798, Loss: 0.568464457988739\n",
      "Epoch: 799, Loss: 0.5684535503387451\n",
      "Epoch: 800, Loss: 0.5684425830841064\n",
      "Epoch: 801, Loss: 0.5684317350387573\n",
      "Epoch: 802, Loss: 0.5684207677841187\n",
      "Epoch: 803, Loss: 0.5684099197387695\n",
      "Epoch: 804, Loss: 0.5683990120887756\n",
      "Epoch: 805, Loss: 0.5683881640434265\n",
      "Epoch: 806, Loss: 0.5683773159980774\n",
      "Epoch: 807, Loss: 0.5683664679527283\n",
      "Epoch: 808, Loss: 0.5683556199073792\n",
      "Epoch: 809, Loss: 0.56834477186203\n",
      "Epoch: 810, Loss: 0.5683339238166809\n",
      "Epoch: 811, Loss: 0.5683231353759766\n",
      "Epoch: 812, Loss: 0.5683123469352722\n",
      "Epoch: 813, Loss: 0.5683014988899231\n",
      "Epoch: 814, Loss: 0.5682907700538635\n",
      "Epoch: 815, Loss: 0.5682799816131592\n",
      "Epoch: 816, Loss: 0.5682691931724548\n",
      "Epoch: 817, Loss: 0.5682584047317505\n",
      "Epoch: 818, Loss: 0.5682477355003357\n",
      "Epoch: 819, Loss: 0.5682370066642761\n",
      "Epoch: 820, Loss: 0.5682262182235718\n",
      "Epoch: 821, Loss: 0.5682154893875122\n",
      "Epoch: 822, Loss: 0.5682047605514526\n",
      "Epoch: 823, Loss: 0.5681940913200378\n",
      "Epoch: 824, Loss: 0.5681833624839783\n",
      "Epoch: 825, Loss: 0.5681726932525635\n",
      "Epoch: 826, Loss: 0.5681620240211487\n",
      "Epoch: 827, Loss: 0.5681514143943787\n",
      "Epoch: 828, Loss: 0.5681407451629639\n",
      "Epoch: 829, Loss: 0.5681301355361938\n",
      "Epoch: 830, Loss: 0.5681194067001343\n",
      "Epoch: 831, Loss: 0.5681087970733643\n",
      "Epoch: 832, Loss: 0.5680981874465942\n",
      "Epoch: 833, Loss: 0.568087637424469\n",
      "Epoch: 834, Loss: 0.568077027797699\n",
      "Epoch: 835, Loss: 0.568066418170929\n",
      "Epoch: 836, Loss: 0.5680558681488037\n",
      "Epoch: 837, Loss: 0.5680453181266785\n",
      "Epoch: 838, Loss: 0.5680347681045532\n",
      "Epoch: 839, Loss: 0.568024218082428\n",
      "Epoch: 840, Loss: 0.568013608455658\n",
      "Epoch: 841, Loss: 0.5680030584335327\n",
      "Epoch: 842, Loss: 0.5679925680160522\n",
      "Epoch: 843, Loss: 0.567982017993927\n",
      "Epoch: 844, Loss: 0.5679715275764465\n",
      "Epoch: 845, Loss: 0.5679610371589661\n",
      "Epoch: 846, Loss: 0.5679506063461304\n",
      "Epoch: 847, Loss: 0.5679400563240051\n",
      "Epoch: 848, Loss: 0.5679295659065247\n",
      "Epoch: 849, Loss: 0.567919135093689\n",
      "Epoch: 850, Loss: 0.5679087042808533\n",
      "Epoch: 851, Loss: 0.5678983330726624\n",
      "Epoch: 852, Loss: 0.5678879618644714\n",
      "Epoch: 853, Loss: 0.567877471446991\n",
      "Epoch: 854, Loss: 0.5678671002388\n",
      "Epoch: 855, Loss: 0.5678567290306091\n",
      "Epoch: 856, Loss: 0.5678463578224182\n",
      "Epoch: 857, Loss: 0.5678359270095825\n",
      "Epoch: 858, Loss: 0.5678255558013916\n",
      "Epoch: 859, Loss: 0.5678152441978455\n",
      "Epoch: 860, Loss: 0.5678048729896545\n",
      "Epoch: 861, Loss: 0.5677945017814636\n",
      "Epoch: 862, Loss: 0.5677841901779175\n",
      "Epoch: 863, Loss: 0.5677738785743713\n",
      "Epoch: 864, Loss: 0.5677635669708252\n",
      "Epoch: 865, Loss: 0.567753255367279\n",
      "Epoch: 866, Loss: 0.5677430033683777\n",
      "Epoch: 867, Loss: 0.5677327513694763\n",
      "Epoch: 868, Loss: 0.567722499370575\n",
      "Epoch: 869, Loss: 0.5677122473716736\n",
      "Epoch: 870, Loss: 0.5677019953727722\n",
      "Epoch: 871, Loss: 0.5676916837692261\n",
      "Epoch: 872, Loss: 0.5676814913749695\n",
      "Epoch: 873, Loss: 0.5676712393760681\n",
      "Epoch: 874, Loss: 0.5676611065864563\n",
      "Epoch: 875, Loss: 0.5676508545875549\n",
      "Epoch: 876, Loss: 0.5676406621932983\n",
      "Epoch: 877, Loss: 0.5676305294036865\n",
      "Epoch: 878, Loss: 0.5676203370094299\n",
      "Epoch: 879, Loss: 0.5676102042198181\n",
      "Epoch: 880, Loss: 0.5676000714302063\n",
      "Epoch: 881, Loss: 0.5675899386405945\n",
      "Epoch: 882, Loss: 0.5675798058509827\n",
      "Epoch: 883, Loss: 0.5675696730613708\n",
      "Epoch: 884, Loss: 0.5675595998764038\n",
      "Epoch: 885, Loss: 0.567549467086792\n",
      "Epoch: 886, Loss: 0.5675393342971802\n",
      "Epoch: 887, Loss: 0.5675293207168579\n",
      "Epoch: 888, Loss: 0.5675191879272461\n",
      "Epoch: 889, Loss: 0.5675092339515686\n",
      "Epoch: 890, Loss: 0.5674991607666016\n",
      "Epoch: 891, Loss: 0.5674890279769897\n",
      "Epoch: 892, Loss: 0.5674790740013123\n",
      "Epoch: 893, Loss: 0.5674690008163452\n",
      "Epoch: 894, Loss: 0.5674590468406677\n",
      "Epoch: 895, Loss: 0.5674489736557007\n",
      "Epoch: 896, Loss: 0.5674390196800232\n",
      "Epoch: 897, Loss: 0.5674290060997009\n",
      "Epoch: 898, Loss: 0.5674191117286682\n",
      "Epoch: 899, Loss: 0.5674091577529907\n",
      "Epoch: 900, Loss: 0.5673991441726685\n",
      "Epoch: 901, Loss: 0.567389190196991\n",
      "Epoch: 902, Loss: 0.5673792958259583\n",
      "Epoch: 903, Loss: 0.5673694014549255\n",
      "Epoch: 904, Loss: 0.5673595070838928\n",
      "Epoch: 905, Loss: 0.5673495531082153\n",
      "Epoch: 906, Loss: 0.5673397183418274\n",
      "Epoch: 907, Loss: 0.5673297643661499\n",
      "Epoch: 908, Loss: 0.567319929599762\n",
      "Epoch: 909, Loss: 0.567310094833374\n",
      "Epoch: 910, Loss: 0.5673002600669861\n",
      "Epoch: 911, Loss: 0.5672903656959534\n",
      "Epoch: 912, Loss: 0.5672805905342102\n",
      "Epoch: 913, Loss: 0.567270815372467\n",
      "Epoch: 914, Loss: 0.5672609806060791\n",
      "Epoch: 915, Loss: 0.5672512054443359\n",
      "Epoch: 916, Loss: 0.5672414302825928\n",
      "Epoch: 917, Loss: 0.5672315955162048\n",
      "Epoch: 918, Loss: 0.5672218203544617\n",
      "Epoch: 919, Loss: 0.5672120451927185\n",
      "Epoch: 920, Loss: 0.5672023296356201\n",
      "Epoch: 921, Loss: 0.5671926140785217\n",
      "Epoch: 922, Loss: 0.5671828389167786\n",
      "Epoch: 923, Loss: 0.5671731233596802\n",
      "Epoch: 924, Loss: 0.5671634078025818\n",
      "Epoch: 925, Loss: 0.5671536922454834\n",
      "Epoch: 926, Loss: 0.5671440958976746\n",
      "Epoch: 927, Loss: 0.5671343207359314\n",
      "Epoch: 928, Loss: 0.567124605178833\n",
      "Epoch: 929, Loss: 0.5671150088310242\n",
      "Epoch: 930, Loss: 0.5671053528785706\n",
      "Epoch: 931, Loss: 0.5670957565307617\n",
      "Epoch: 932, Loss: 0.5670861005783081\n",
      "Epoch: 933, Loss: 0.5670764446258545\n",
      "Epoch: 934, Loss: 0.5670669078826904\n",
      "Epoch: 935, Loss: 0.5670573115348816\n",
      "Epoch: 936, Loss: 0.5670477151870728\n",
      "Epoch: 937, Loss: 0.5670381188392639\n",
      "Epoch: 938, Loss: 0.5670284628868103\n",
      "Epoch: 939, Loss: 0.5670188665390015\n",
      "Epoch: 940, Loss: 0.5670093894004822\n",
      "Epoch: 941, Loss: 0.5669998526573181\n",
      "Epoch: 942, Loss: 0.5669902563095093\n",
      "Epoch: 943, Loss: 0.56698077917099\n",
      "Epoch: 944, Loss: 0.5669712424278259\n",
      "Epoch: 945, Loss: 0.5669618248939514\n",
      "Epoch: 946, Loss: 0.5669523477554321\n",
      "Epoch: 947, Loss: 0.5669428706169128\n",
      "Epoch: 948, Loss: 0.5669333338737488\n",
      "Epoch: 949, Loss: 0.5669239163398743\n",
      "Epoch: 950, Loss: 0.566914439201355\n",
      "Epoch: 951, Loss: 0.5669050216674805\n",
      "Epoch: 952, Loss: 0.5668955445289612\n",
      "Epoch: 953, Loss: 0.5668861269950867\n",
      "Epoch: 954, Loss: 0.5668767094612122\n",
      "Epoch: 955, Loss: 0.5668674111366272\n",
      "Epoch: 956, Loss: 0.5668579339981079\n",
      "Epoch: 957, Loss: 0.5668485760688782\n",
      "Epoch: 958, Loss: 0.5668391585350037\n",
      "Epoch: 959, Loss: 0.5668298006057739\n",
      "Epoch: 960, Loss: 0.5668204426765442\n",
      "Epoch: 961, Loss: 0.5668111443519592\n",
      "Epoch: 962, Loss: 0.5668017864227295\n",
      "Epoch: 963, Loss: 0.5667924284934998\n",
      "Epoch: 964, Loss: 0.56678307056427\n",
      "Epoch: 965, Loss: 0.5667737722396851\n",
      "Epoch: 966, Loss: 0.5667645335197449\n",
      "Epoch: 967, Loss: 0.5667552351951599\n",
      "Epoch: 968, Loss: 0.566745936870575\n",
      "Epoch: 969, Loss: 0.56673663854599\n",
      "Epoch: 970, Loss: 0.5667274594306946\n",
      "Epoch: 971, Loss: 0.5667182207107544\n",
      "Epoch: 972, Loss: 0.5667089223861694\n",
      "Epoch: 973, Loss: 0.5666996836662292\n",
      "Epoch: 974, Loss: 0.5666904449462891\n",
      "Epoch: 975, Loss: 0.5666812658309937\n",
      "Epoch: 976, Loss: 0.5666720867156982\n",
      "Epoch: 977, Loss: 0.5666629076004028\n",
      "Epoch: 978, Loss: 0.5666536688804626\n",
      "Epoch: 979, Loss: 0.566644549369812\n",
      "Epoch: 980, Loss: 0.5666353106498718\n",
      "Epoch: 981, Loss: 0.566626250743866\n",
      "Epoch: 982, Loss: 0.5666170716285706\n",
      "Epoch: 983, Loss: 0.5666078925132751\n",
      "Epoch: 984, Loss: 0.5665988326072693\n",
      "Epoch: 985, Loss: 0.5665897130966187\n",
      "Epoch: 986, Loss: 0.566580593585968\n",
      "Epoch: 987, Loss: 0.5665714740753174\n",
      "Epoch: 988, Loss: 0.5665624141693115\n",
      "Epoch: 989, Loss: 0.5665533542633057\n",
      "Epoch: 990, Loss: 0.5665442943572998\n",
      "Epoch: 991, Loss: 0.5665351748466492\n",
      "Epoch: 992, Loss: 0.5665262341499329\n",
      "Epoch: 993, Loss: 0.5665171146392822\n",
      "Epoch: 994, Loss: 0.5665080547332764\n",
      "Epoch: 995, Loss: 0.5664990544319153\n",
      "Epoch: 996, Loss: 0.5664900541305542\n",
      "Epoch: 997, Loss: 0.5664810538291931\n",
      "Epoch: 998, Loss: 0.566472053527832\n",
      "Epoch: 999, Loss: 0.5664631128311157\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optim.zero_grad()\n",
    "    forward_output = model(X_train_tensor)\n",
    "    cost = loss(forward_output, Y_train_tensor)\n",
    "    cost.backward()\n",
    "    optim.step()\n",
    "\n",
    "    print(f'Epoch: {epoch}, Loss: {cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "77cvfzJWok6f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VOCOIOkba7Qi",
    "outputId": "58554466-48bf-4db5-eccc-ffef14f95a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_output = model(X_test_tensor)\n",
    "max_value, outputs = torch.max(model_output, 1)\n",
    "acc = accuracy_score(Y_test_tensor, outputs)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "yHwuewbIc6RE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
